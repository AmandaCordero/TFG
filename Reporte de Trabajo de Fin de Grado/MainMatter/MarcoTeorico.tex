%===================================================================================
% Chapter: Marco Teorico
%===================================================================================
\chapter{Preliminares}\label{chapter:preliminares}
%\addcontentsline{toc}{chapter}{Marco Teórico}
%===================================================================================

En este capítulo se sientan las bases para el desarrollo de la investigación.

\section{Perspectiva Inmunológica}

\textit{Streptococcus pneumoniae} es una bacteria Gram-positiva, encapsulada y con forma lanceolada, que coloniza las vías respiratorias superiores en humanos. Es un patógeno de relevancia clínica global, asociado tanto a enfermedades invasivas (como meningitis, neumonía bacteriémica y sepsis) como a infecciones no invasivas (otitis media aguda y sinusitis) \cite{WHO2019}.



\subsection{Características clave}
\begin{itemize}
    \item \textbf{Variabilidad serotípica}: Existen más de 90 serotipos\footnote{Microorganismo infeccioso clasificado según los antígenos presentes en su superficie celular.} diferenciados por la composición de su cápsula polisacárida, aunque apenas 12 de ellos son responsables de mas del 80\% de las infecciones neumocóccicas invasoras \cite{PREADOJ2001}
    \item \textbf{Poblaciones vulnerables}: Lactantes, adultos mayores (mayores de 65 años) e individuos inmunocomprometidos presentan mayor riesgo de infección grave.
\end{itemize}

\subsubsection{Importancia de la vacunación}
La diversidad de serotipos y la emergencia de cepas resistentes a antibióticos subrayan la importancia de estrategias preventivas como la vacunación. Las vacunas conjugadas han demostrado reducir significativamente la incidencia de enfermedad neumocócica al inducir inmunidad específica frente a los serotipos más prevalentes \cite{Snedecor2020a}.

\subsection{Inmunología básica}

El sistema inmunitario humano responde a \textit{Streptococcus pneumoniae} mediante dos grandes componentes \cite{AEP2022}:

\begin{itemize}
    \item \textbf{Inmunidad innata}: Primera línea de defensa, compuesta por células como neutrófilos, macrófagos y células dendríticas, así como factores humorales como el sistema del complemento.
    \item \textbf{Inmunidad adaptativa}: Proporciona especificidad y memoria inmunológica, mediada por linfocitos T (CD4$^+$, CD8$^+$) y B.
\end{itemize}

\subsubsection{Respuesta inmune a \textit{Streptococcus pneumoniae}: linfocitos B, memoria inmunológica y anticuerpos}

Los linfocitos B son fundamentales en la defensa frente a \textit{Streptococcus pneumoniae}, especialmente tras la vacunación:
\begin{itemize}
    \item Producen anticuerpos específicos que neutralizan al patógeno.
    \item Experimentan maduración de afinidad y cambio de isotipo (por ejemplo, de IgM a IgG).
    \item Generan células de memoria que permiten una respuesta más rápida y eficaz ante exposiciones futuras.
\end{itemize}

\subsubsection{Características inmunológicas en lactantes}
\begin{itemize}
    \item \textbf{Anticuerpos maternos}: 
    \begin{itemize}
        \item Transferencia placentaria de IgG (especialmente IgG1) mediante el receptor FcRn.
        \item Protección adicional a través de IgA secretora en la leche materna.
        \item Posible \textit{blunting} (interferencia de anticuerpos maternos con la respuesta vacunal), aunque su impacto clínico es limitado.\cite{AEP2023Blunting}
    \end{itemize}
    \item \textbf{Desarrollo inmune}: El sistema inmunitario neonatal es funcional pero inmaduro, dependiendo inicialmente de la inmunidad materna.
\end{itemize}

\subsubsection{Definiciones clave}
\begin{itemize}
    \item \textbf{Inmunogenicidad}: Capacidad de una vacuna para inducir una respuesta inmunitaria medible (por ejemplo, producción de anticuerpos).
    \item \textbf{Efectividad clínica}: Protección real conferida contra la enfermedad en condiciones del mundo real.
    \item \textbf{Conjugación proteica}: Las vacunas conjugadas unen polisacáridos capsulares a proteínas transportadoras para potenciar la respuesta inmunitaria, especialmente en niños pequeños.
\end{itemize}

\subsection{Vacunas antineumocócicas conjugadas}


Las vacunas antineumocócicas conjugadas (PCV por sus siglas en inglés) emplean polisacáridos capsulares conjugados a proteínas para inducir una respuesta inmunitaria robusta y duradera y generar memoria inmunológica mediante la activación de linfocitos T y B.


\subsubsection{Cobertura y correlatos de protección}
Las formulaciones actuales de PCV cubren los serotipos más prevalentes y virulentos. Los correlatos de protección\footnote{Mediciones de parámetros inmunitarios que permiten predecir el grado de protección contra la infección o enfermedad inducida por un patógeno.} pueden variar según el serotipo y la vacuna específica, y son utilizados como criterios en ensayos clínicos y en la evaluación de programas de vacunación \cite{Snedecor2020a}.

\subsection{Examen ELISA}

El examen ELISA (Ensayo de Inmunoabsorción Ligado a Enzima) es una técnica inmunoenzimática ampliamente utilizada para la detección y cuantificación específica de antígenos o anticuerpos en muestras biológicas. El principio fundamental del ELISA se basa en la unión específica entre un anticuerpo y un antígeno, donde uno de estos componentes está inmovilizado en una superficie sólida, generalmente una placa de microtitulación.

La detección se realiza mediante un anticuerpo conjugado con una enzima, que al reaccionar con un sustrato específico produce un cambio de color proporcional a la cantidad de analito presente en la muestra. Este cambio es medido espectrofotométricamente, permitiendo cuantificar la concentración del antígeno o anticuerpo.

Existen diferentes formatos de ELISA, entre ellos:

\begin{itemize}
    \item \textbf{ELISA directo}: el anticuerpo marcado con enzima se une directamente al antígeno inmovilizado.
    \item \textbf{ELISA indirecto}: utiliza un anticuerpo primario para detectar el antígeno y un anticuerpo secundario marcado con enzima para amplificar la señal.
    \item \textbf{ELISA sándwich}: un anticuerpo captura el antígeno, y otro anticuerpo marcado con enzima detecta el antígeno capturado, aumentando la sensibilidad y especificidad.
    \item \textbf{ELISA competitivo}: el antígeno en la muestra compite con un antígeno marcado por la unión a un anticuerpo específico.
\end{itemize}

Esta técnica es fundamental en diagnóstico clínico, investigación biomédica y control de calidad, debido a su alta sensibilidad, especificidad y rapidez \cite{Lequin2005}.

\section{Perspectiva Matemático-Computacional}
En esta sección se analizan los conceptos teóricos sobre los que se fundamenta esta investigación. Temas como: Metaheurísticas, métricas de similitud y concurrencia serán tratados en las siguientes subsecciones.


\subsection{Metaheurísticas}
\label{sec:metaheuristicas}

Las metaheurísticas son estrategias de alto nivel diseñadas para encontrar soluciones aproximadas a problemas de optimización complejos, especialmente aquellos donde los métodos exactos son computacionalmente inviables. Estas técnicas, inspiradas frecuentemente en procesos naturales o comportamientos sociales, exploran espacios de soluciones de manera inteligente para escapar de óptimos locales y aproximarse al óptimo global \cite{Talbi2009}.

% \subsubsection{Características Fundamentales}
% Las metaheurísticas comparten propiedades clave que las distinguen de otros métodos de optimización:

% \begin{itemize}
%     \item \textbf{Alto nivel de abstracción}: Independientes del problema específico
%     \item \textbf{Tolerancia a la no linealidad}: Manejan funciones objetivo discontinuas o no diferenciables
%     \item \textbf{Exploración-estratificada}: Balance entre diversificación (exploración) e intensificación (explotación)
%     \item \textbf{Algoritmos no deterministas}: Incorporan elementos estocásticos
%     \item \textbf{Bajo requerimiento de información}: No necesitan gradientes ni propiedades matemáticas específicas
% \end{itemize}


A continuación se presentan algunas de las metaheurísticas más conocidas:

\subsubsection{Recocido Simulado (Simulated Annealing)}
\label{subsec:recocido-simulado}

Inspirado en el proceso metalúrgico de recocido, donde un material se calienta y luego se enfría gradualmente para reducir sus defectos \cite{Kirkpatrick1983}. Este método:

\begin{itemize}
    \item Comienza con una solución inicial $s_0$ y temperatura alta $T_0$
    \item En cada iteración, genera una solución vecina $s'$
    \item Acepta soluciones mejores ($f(s') < f(s)$) siempre
    \item Acepta soluciones peores con probabilidad $P = e^{-\Delta f / T}$ donde $\Delta f = f(s') - f(s)$
    \item Reduce temperatura gradualmente según esquema $T_{k+1} = \alpha T_k$ ($\alpha \in (0,1)$)
\end{itemize}

La curva de enfriamiento (disminución de $T$) controla el balance exploración-explotación:

\begin{equation}
T(k) = \frac{T_0}{\ln(1 + k)} \quad \text{(esquema logarítmico)}
\end{equation}



\subsubsection{Algoritmos Genéticos (Genetic Algorithms)}
\label{subsec:algoritmos-geneticos}

Basados en la evolución biológica mediante selección natural \cite{Holland1992}.

\begin{itemize}
    \item Representan soluciones como cromosomas (vectores)
    \item Operadores clave:
    \begin{itemize}
        \item \textbf{Selección}: Prefiere soluciones con mejor \textit{fitness}
        \item \textbf{Cruzamiento}: Combina partes de dos soluciones
        \item \textbf{Mutación}: Modifica aleatoriamente componentes
    \end{itemize}
    \item Mantienen una población de soluciones diversa
    \item Reemplazo generacional o estado estable
\end{itemize}

La aptitud (fitness) de una solución $s_i$ se calcula como:
\begin{equation}
fitness(s_i) = \frac{1}{1 + f(s_i)}
\end{equation}


\subsubsection{Optimización por Colonia de Hormigas (Ant Colony Optimization)}
\label{subsec:tabu-search}

La Optimización por Colonia de Hormigas es una metaheurística bioinspirada que emula el comportamiento colectivo de las hormigas reales en su búsqueda de caminos óptimos hacia fuentes de alimento. Cuando las hormigas exploran su entorno, depositan sustancias químicas llamadas feromonas que sirven como señalización para otras hormigas \cite{Dorigo1996}. Este mecanismo de comunicación indirecta (estigmergia) permite a la colonia encontrar rutas eficientes mediante:
\begin{itemize}
    
    \item Retroalimentación positiva: Caminos más cortos acumulan más feromonas al ser transitados más frecuentemente
    \item Evaporación dinámica: Las feromonas se evaporan gradualmente, evitando convergencia prematura
    \item Exploración estocástica: Decisiones basadas en probabilidades que balancean explotación y exploración
\end{itemize}

El proceso sigue estos pasos iterativos:

\begin{enumerate}
    \item \textit{Inicialización}: Feromonas uniformes en todos los caminos ($\tau_{ij} = \tau_0$)
    \item \textit{Construcción de soluciones}: Cada hormiga $k$ construye una solución completa mediante selección probabilística:
    \[
    p_{ij}^k = \frac{[\tau_{ij}]^\alpha \cdot [\eta_{ij}]^\beta}{\sum_{l \in N_i^k} [\tau_{il}]^\alpha \cdot [\eta_{il}]^\beta}
    \]
    donde $\eta_{ij}$ es información heurística (ej. $1/d_{ij}$)
    \item \textit{Actualización de feromonas}: Combinación de evaporación y depósito:
    \[
    \tau_{ij} \leftarrow (1 - \rho) \cdot \tau_{ij} + \sum_{k=1}^m \Delta \tau_{ij}^k
    \]
    \[
    \Delta \tau_{ij}^k = 
    \begin{cases} 
    Q/L_k & \text{si la hormiga } k \text{ usó } (i,j) \\
    0 & \text{otro caso}
    \end{cases}
    \]
    \item \textit{Reforzamiento elitista}: Las mejores soluciones históricas reciben depósito adicional
\end{enumerate}

\subsection{Métricas para comparar conjuntos (nubes) de puntos}


Para evaluar la similitud entre dos nubes de puntos, se utilizan diversas métricas según el contexto de análisis. A continuación se presentan los métodos más relevantes:

\subsubsection{Distancia Euclidiana Promedio}
\label{subsec:dist-euclid}
Mide la proximidad espacial absoluta entre puntos correspondientes:
\begin{equation}
D_{\text{avg}} = \frac{1}{n} \sum_{i=1}^n \sqrt{(x_i - x'_i)^2 + (y_i - y'_i)^2}
\end{equation}

\textbf{Características:}
\begin{itemize}
    \item Interpretación física directa (unidades espaciales)
    \item Sensible a traslaciones globales
    \item Cálculo computacionalmente eficiente $O(n)$
\end{itemize}

\subsubsection{Similitud del Coseno}
\label{subsec:cos-sim}
Evalúa la orientación relativa de los vectores posición, independiente de su magnitud:
\begin{equation}
S_{\cos} = \frac{\sum_{i=1}^n (x_i x'_i + y_i y'_i)}{\sqrt{\sum_{i=1}^n (x_i^2 + y_i^2)} \cdot \sqrt{\sum_{i=1}^n ({x'_i}^2 + {y'_i}^2)}}
\end{equation}

\textbf{Aplicaciones:}
\begin{itemize}
    \item Comparación de formas geométricas
    \item Análisis donde la posición absoluta es irrelevante
    \item Sistemas de coordenadas relativas
\end{itemize}

\subsubsection{Métrica Basada en Trabajo de Transformación}
\label{subsec:work-metric}
Calcula la energía requerida para transformar una nube en otra:
\begin{equation}
S_{\%} = 100 \cdot \left(1 - \frac{W}{W_{\max}}\right)
\end{equation}
donde $W$ es el trabajo computado y $W_{\max}$ el trabajo máximo teórico.

\textbf{Implementación:}
\begin{enumerate}
    \item Calcular la transformación óptima (traslación, rotación)
    \item Integrar las diferencias posicionales residuales
    \item Normalizar respecto a la peor transformación posible
\end{enumerate}


\subsubsection{Métricas de Clustering}
\label{subsec:cluster-metrics}
Evalúan relaciones intra e inter-conjuntos:
\begin{align}
D_{\text{intra}}^A &= \frac{1}{n(n-1)} \sum_{i \neq j} \|p_i^A - p_j^A\| \\
D_{\text{inter}}^{\min} &= \min_{i,j} \|p_i^A - p_j^B\| \\
H_{\text{hausdorff}} &= \max\left( \sup_{a \in A} \inf_{b \in B} \|a-b\|, \sup_{b \in B} \inf_{a \in A} \|a-b\| \right)
\end{align}

\textbf{Interpretación:}
\begin{itemize}
    \item $D_{\text{intra}}$: Compacidad de cada nube
    \item $D_{\text{inter}}^{\min}$: Proximidad mínima entre nubes
    \item $H_{\text{hausdorff}}$: Máxima discrepancia entre fronteras
\end{itemize}

\subsubsection{Distancia Chamfer}
Cuantifica la similitud entre dos conjuntos de puntos en el espacio. Evalúa la proximidad bidireccional entre cada punto de un conjunto y su vecino más cercano en el otro conjunto.

El cálculo de la distancia de Chamfer se realiza en dos pasos principales:

\begin{enumerate}
    \item Para cada punto en el primer conjunto, se encuentra el punto más cercano en el segundo conjunto y se calcula la distancia euclidiana entre ellos. Se obtiene el promedio de estas distancias.
    \item Se repite el procedimiento invirtiendo los roles de los conjuntos, es decir, desde el segundo conjunto hacia el primero.
\end{enumerate}

Se define como la suma (o promedio) de estos dos valores, formalmente expresada como:
\[
D_{\mathrm{Chamfer}}(S_1, S_2) = \frac{1}{|S_1|} \sum_{x \in S_1} \min_{y \in S_2} \|x - y\|_2 \;+\; \frac{1}{|S_2|} \sum_{y \in S_2} \min_{x \in S_1} \|y - x\|_2
\]
donde \(\|\cdot\|_2\) denota la distancia euclidiana.

Esta métrica es relevante porque permite evaluar de forma robusta la similitud entre nubes de puntos, incluso cuando los estos no están emparejados uno a uno. 

\subsection{Distribución de Boltzmann}

La \textbf{distribución de Boltzmann} es un concepto fundamental en física estadística que describe cómo las partículas en un sistema en equilibrio térmico distribuyen su energía entre los diferentes estados accesibles \cite{Reif1965}. Esta distribución establece que la probabilidad de encontrar una partícula en un estado con energía $ E_i $ a una temperatura $ T $ está dada por:

\begin{equation}
    P(E_i) = \frac{1}{Z} g_i e^{-\frac{E_i}{k_B T}}
\end{equation}
donde:

    
- $ P(E_i) $: probabilidad del estado con energía $ E_i $,
    
- $ g_i $: degeneración del nivel de energía (número de estados con la misma energía),
    
- $ k_B $: constante de Boltzmann,
    
- $ T $: temperatura absoluta,
    
- $ Z $: función de partición, definida como $ Z = \sum_i g_i e^{-\frac{E_i}{k_B T}} $, y que normaliza la distribución para que la suma de todas las probabilidades sea igual a uno.


Esta distribución es válida para sistemas clásicos en equilibrio térmico y es especialmente útil cuando las partículas son distinguibles y las interacciones entre ellas pueden considerarse débiles o promediadas. 

\subsection{Acercamiento a la concurrencia}
La programación concurrente es un paradigma esencial para maximizar la eficiencia en sistemas modernos, permitiendo la ejecución aparentemente simultánea de múltiples tareas. Su dominio es crucial para desarrollar aplicaciones escalables y receptivas, aunque introduce complejidades que requieren técnicas especializadas para garantizar la corrección y estabilidad del software. Los contenido tratados en lo adelante están fundamentados en lo tratado en \cite{tanenbaum2008modern}.

\subsubsection{Concurrencia vs. Paralelismo}
La concurrencia y el paralelismo son conceptos fundamentales en la programación moderna, aunque a menudo se confunden debido a su estrecha relación. La concurrencia se refiere a la capacidad de gestionar múltiples tareas de forma que parezcan avanzar al mismo tiempo, aunque no necesariamente se ejecuten simultáneamente. Esto se logra mediante la planificación eficiente del procesador, donde un único núcleo puede alternar entre diferentes tareas en intervalos de tiempo muy pequeños, creando la ilusión de ejecución simultánea. La concurrencia permite que varias tareas progresen de manera ordenada incluso cuando compiten por recursos limitados.

Por otro lado, el paralelismo implica la ejecución real y simultánea de múltiples tareas utilizando recursos físicos separados, como varios núcleos de CPU o dispositivos de cómputo dedicados. Su enfoque está orientado a acelerar procesos computacionalmente intensivos dividiendo el trabajo en partes que pueden resolverse en paralelo. Aunque todo paralelismo implica concurrencia, ya que las tareas deben coordinarse, no toda concurrencia requiere paralelismo. Esta distinción es crucial a la hora de diseñar sistemas que prioricen el rendimiento o la interacción con el usuario.

\subsubsection{Hilos}
Un hilo (\textit{thread}) es la unidad básica de ejecución dentro de un proceso, gestionada directamente por el sistema operativo. Los hilos permiten dividir un programa en componentes que pueden ejecutarse concurrentemente, lo que resulta especialmente útil para tareas que requieren manejo simultáneo de distintas operaciones. Una característica clave de los hilos es que comparten el espacio de memoria y los recursos del proceso padre, lo cual facilita la comunicación entre ellos, pero también introduce desafíos relacionados con la consistencia de datos.



\subsubsection{Retos en Programación Concurrente}
La programación concurrente presenta una serie de desafíos, siendo uno de los más comunes la condición de carrera (\textit{race condition}). Este fenómeno ocurre cuando dos o más hilos intentan acceder y modificar un recurso compartido simultáneamente, causando resultados inconsistentes o impredecibles. Para evitar este tipo de problemas, se utiliza la exclusión mutua, que garantiza que solo un hilo pueda acceder a un recurso crítico en un momento dado.

Entre las herramientas más utilizadas para implementar exclusión mutua están los semáforos, \textit{mutex} y monitores. Estas estructuras permiten controlar el acceso a secciones críticas del código y asegurar la integridad de los datos compartidos. 
Sin embargo, su uso incorrecto puede llevar a otro problema conocido como interbloqueo (\textit{deadlock}), que sucede cuando dos o más hilos quedan esperando indefinidamente por recursos que nunca serán liberados porque cada uno posee un recurso que el otro necesita. 
% \subsection{Conceptos Fundamentales de Concurrencia}
% \label{sec:fundamentos-concurrencia}

% \subsubsection{Concurrencia y Paralelismo}
% La \textbf{concurrencia} es la capacidad de un sistema para gestionar múltiples tareas \textit{aparentemente} simultáneas, mientras que el \textbf{paralelismo} implica la ejecución \textit{real simultánea} de tareas. Matemáticamente, para $n$ tareas:

% \begin{equation}
% \text{Concurrencia} \subseteq \{ \text{Interleaving} \cup \text{Paralelismo} \}
% \end{equation}

% El paralelismo requiere múltiples unidades de procesamiento (e.g., núcleos de CPU), mientras que la concurrencia puede lograrse en un solo núcleo mediante planificación.

% \subsubsection{Hilos (Threads)}
% Los \textbf{hilos} son la unidad básica de ejecución dentro de un proceso. Comparten memoria pero tienen stacks propios. Un conjunto de hilos se define como:

% \begin{lstlisting}[language=C++,caption=Creación de hilos en C++]
% #include <thread>
% void tarea() { /* ... */ }

% int main() {
%     std::thread hilo1(tarea);  // Hilo secundario
%     std::thread hilo2(tarea);
    
%     hilo1.join();  // Sincronización
%     hilo2.join();
% }
% \end{lstlisting}

% \subsubsection{Condición de Carrera (Race Condition)}
% Ocurre cuando múltiples hilos acceden concurrentemente a recursos compartidos \textbf{sin sincronización}, y el resultado depende del orden de ejecución. Formalmente:

% \[
% \text{Race Condition} \iff \exists \, r_i, r_j \in \text{Accesos} \mid (r_i \parallel r_j) \land \neg \text{Ordenado}
% \]

% \subsubsection{Sección Crítica}
% Segmento de código donde se accede a recursos compartidos que deben protegerse. Debe satisfacer tres propiedades:
% \begin{enumerate}
%     \item \textbf{Exclusión mutua}: Solo un hilo puede ejecutarla
%     \item \textbf{Progreso}: Si no hay hilos en SC, algún hilo puede entrar
%     \item \textbf{Espera acotada}: Número máximo de espera es finito
% \end{enumerate}

% \subsubsection{Exclusión Mutua}
% Mecanismo para garantizar que solo un hilo acceda a la sección crítica. Implementaciones comunes:

% \begin{itemize}
%     \item \textbf{Mutex}: Bloqueo binario
%     \begin{lstlisting}[language=Python]
% import threading
% mutex = threading.Lock()

% mutex.acquire()
% # Sección crítica
% mutex.release()
%     \end{lstlisting}
    
%     \item \textbf{Semáforos}: Contador para $n$ accesos
%     \item \textbf{Monitores}: Abstracción de alto nivel
% \end{itemize}

% \subsubsection{Interbloqueo (Deadlock)}
% Situación donde múltiples procesos/hilos se bloquean mutuamente esperando recursos. Requiere cuatro condiciones (Coffman):
% \begin{enumerate}
%     \item \textbf{Exclusión mutua}: Recurso no compartible
%     \item \textbf{Retención y espera}: Mantener recursos mientras se esperan otros
%     \item \textbf{No expropiación}: Los recursos no pueden ser forzosamente liberados
%     \item \textbf{Espera circular}: Ciclo de dependencias
% \end{enumerate}

% El deadlock puede modelarse como grafo dirigido donde $P \to R$ indica que proceso $P$ solicita recurso $R$, y $R \to P$ indica que $R$ está asignado a $P$. Un ciclo implica deadlock.

% \subsubsection{Técnicas de Prevención}
% \begin{table}[h]
% \centering
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Técnica} & \textbf{Ventajas} & \textbf{Desventajas} \\ \hline
% Evitar espera circular & Sin deadlock & Baja utilización recursos \\ \hline
% Expropiación & Flexibilidad & Complejidad implementación \\ \hline
% Espera acotada & Determinismo & Difícil estimación \\ \hline
% \end{tabular}
% \caption{Comparación de técnicas anti-deadlock}
% \end{table}
% \end{section}

% \section{Paralelismo y Concurrencia en Sistemas Distribuidos}
% \label{sec:paralelismo}

% La computación moderna requiere el manejo eficiente de operaciones simultáneas, lo que ha impulsado el desarrollo de técnicas de paralelismo y concurrencia. Estas permiten ejecutar múltiples tareas de forma coordinada, optimizando el uso de recursos computacionales.

% \subsection{Conceptos Fundamentales}
% \begin{itemize}
%     \item \textbf{Paralelismo}: Ejecución simultánea de tareas en múltiples procesadores o núcleos.
%     \item \textbf{Concurrencia}: Capacidad de gestionar múltiples tareas que progresan solapadamente en el tiempo.
%     \item \textbf{Hilos}: Unidad básica de ejecución dentro de un proceso que comparte espacio de memoria.
% \end{itemize}

% \subsection{Retos en Programación Concurrente}
% \label{subsec:retos}

% \subsubsection{Condiciones de Carrera}
% Ocurren cuando múltiples hilos acceden concurrentemente a recursos compartidos sin sincronización adecuada, llevando a resultados impredecibles. Por ejemplo:

% \begin{lstlisting}[language=C,caption=Ejemplo de condición de carrera]
% int contador = 0;

% void* incrementar() {
%     for(int i=0; i<1000; i++){
%         contador++; // Operación no atómica
%     }
% }
% \end{lstlisting}

% \subsubsection{Secciones Críticas}
% Regiones de código que acceden a recursos compartidos y requieren ejecución atómica. Su manejo inadecuado puede generar:

% \begin{itemize}
%     \item \textbf{Interbloqueo}: Situación donde dos o más procesos se bloquean mutuamente esperando recursos.
%     \item \textbf{Inanición}: Imposibilidad de un proceso para acceder a recursos necesarios.
% \end{itemize}

% \subsection{Exclusión Mutua}
% \label{subsec:exclusion}

% Mecanismo fundamental para garantizar que solo un hilo acceda a una sección crítica simultáneamente. Debe cumplir cuatro propiedades esenciales:

% \begin{enumerate}
%     \item Exclusión mutua: Máximo un hilo en la sección crítica
%     \item Progreso: Decisión de entrada en tiempo finito
%     \item Espera limitada: Cota máxima de espera para cualquier hilo
%     \item Neutralidad: No asumir velocidades de procesador
% \end{enumerate}

% \subsubsection{Técnicas de Implementación}
% \begin{table}[h]
% \centering
% \caption{Comparación de métodos de exclusión mutua}
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Método} & \textbf{Ventajas} & \textbf{Limitaciones} \\ \hline
% Semáforos & Sincronización flexible & Complejidad de uso \\ \hline
% Monitores & Encapsulación natural & Soporte lenguaje requerido \\ \hline
% Mutex & Bajo overhead & Solo exclusión binaria \\ \hline
% \end{tabular}
% \end{table}

% \subsubsection{Algoritmos Clásicos}
% \begin{itemize}
%     \item Algoritmo de Peterson (solución software para dos procesos)
%     \item Semáforos de Dijkstra (sincronización generalizada)
%     \item Cerrojos adaptativos (spinlocks + bloqueo kernel)
% \end{itemize}

% \subsection{Consideraciones de Diseño}
% La gestión efectiva de la concurrencia requiere:
% \begin{itemize}
%     \item Análisis de granularidad de bloqueos
%     \item Patrones de diseño como productor-consumidor
%     \item Detección temprana de interbloqueos mediante grafos de asignación
%     \item Uso de herramientas de análisis estático (ej. ThreadSanitizer)
% \end{itemize}

% Este conjunto de técnicas y consideraciones constituye la base para construir sistemas concurrentes robustos y eficientes, particularmente relevantes en entornos distribuidos y de alto rendimiento.
